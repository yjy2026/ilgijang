- 2022/09/24 
    - 큰 LM 의 pretrain 이 안될때는 일단 작은 LM 부터 학습해서, weight 를 큰 LM 의 Parameter 로 옮겨서 또 학습하고...
    - 이걸 반복해서 목표로 하는 거대 LM 학습으로 가져가자.
- 2022/12/09
    - chobig 모델들이 어느정도 틀이 갖춰진 듯 하다.
    - 이제 좀 논문 읽기가 하고 싶을지도?
    - 근데 북커톤..
- 2023/01/05
    - 북커톤 다신 안함
    - HuggingFace 의 BigBird 는 attention_type 이 block_sparse 일 때 is_decoder 로 decoder 로의 변경이 불가함. (<-- 당연한건데, 그냥 내가 안일했음)
    - GPT 더 큰거, 더 작은거 학습하자.
